{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddaf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries and Visualizing Data\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from ta.momentum import RSIIndicator\n",
    "\n",
    "random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "np.random.seed(7)\n",
    "tf.compat.v1.set_random_seed(7)\n",
    "\n",
    "os.chdir(\"C:/Programming/Stock prediction\") #set your own working directory\n",
    "\n",
    "# load & preprocess data function\n",
    "def load_stock_data(filename=\"AAPL.csv\"):\n",
    "    df = pd.read_csv(filename)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    df['volatility_5d'] = np.log(df['close'] / df['close'].shift(1)).rolling(window=5).std()\n",
    "    df['volatility_21d'] = np.log(df['close'] / df['close'].shift(1)).rolling(window=21).std()\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def plot_returns_and_volatility(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['date'], df['log_return'], label=\"Daily Log Return\", color='skyblue', alpha=0.7)\n",
    "    plt.title(\"Apple Daily Log Returns\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Log Return\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['date'], df['volatility_5d'], label=\"5-Day Volatility\", color='blue', alpha=0.8)\n",
    "    plt.plot(df['date'], df['volatility_21d'], label=\"21-Day Volatility\",color='orange', alpha=0.8)\n",
    "    plt.title(\"Realized Volatility (5-day vs 21-day)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Volatility\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df = load_stock_data(\"AAPL.csv\")\n",
    "plot_returns_and_volatility(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and training\n",
    "# feature engineering function\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    df['lag1'] = df['log_return'].shift(1)\n",
    "    df['lag2'] = df['log_return'].shift(2)\n",
    "    df['r2'] = df['log_return']**2\n",
    "    df['z_log_return'] = (df['log_return'] - df['log_return'].rolling(21).mean()) / df['log_return'].rolling(21).std()\n",
    "    df['price_shock'] = (df['log_return'].abs() > 2 * df['log_return'].rolling(21).std()).astype(int)\n",
    "    df['rsi'] = RSIIndicator(close=df['close'], window=14).rsi()\n",
    "    df['log_volume_change'] = np.log(df['volume'] / df['volume'].shift(1))\n",
    "    df['log_range'] = np.log(df['high'] / df['low'])\n",
    "    df['vol_5'] = df['log_return'].rolling(window=5).std()\n",
    "    df['volatility_7'] = df['log_return'].rolling(window=7).std()\n",
    "    df['volatility_21'] = df['log_return'].rolling(window=21).std()\n",
    "    df['future_vol'] = df['log_return'].rolling(window=5).std().shift(-5)    \n",
    "    return df.dropna().reset_index(drop=True)\n",
    "\n",
    "data = add_features(df)\n",
    "\n",
    "# sequence generator\n",
    "def create_sequences(train_x_scaled, train_y_scaled, seq_length):\n",
    "    train_seq_x, train_seq_y = [], []\n",
    "    for i in range(seq_length, len(train_x_scaled)):\n",
    "        train_seq_x.append(train_x_scaled[i - seq_length:i])\n",
    "        train_seq_y.append(train_y_scaled[i])\n",
    "    return np.array(train_seq_x), np.array(train_seq_y)\n",
    "\n",
    "# build model\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(80, return_sequences=True, input_shape=input_shape)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(100, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(120),\n",
    "        Dropout(0.3),\n",
    "        Dense(32),\n",
    "        Dense(1)])\n",
    "    return model\n",
    "\n",
    "# compile model\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=[RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "# load and process dataset\n",
    "seq_length = 45\n",
    "x = ['log_return','lag1', 'lag2','r2',\n",
    "    'z_log_return', 'price_shock','rsi',\n",
    "    'log_volume_change', 'log_range',\n",
    "    'vol_5', 'volatility_7', 'volatility_21']\n",
    "y = 'future_vol'\n",
    "    \n",
    "# split data\n",
    "num_samples = len(data)\n",
    "train_cutoff = int(num_samples * 0.6)\n",
    "test_cutoff = int(num_samples * 0.8)\n",
    "\n",
    "train_data = data.iloc[:train_cutoff]\n",
    "test_data = data.iloc[train_cutoff:test_cutoff]\n",
    "out_of_sample_data = data.iloc[test_cutoff:]\n",
    "\n",
    "train_y = train_data[[y]].values\n",
    "test_y = test_data[[y]].values\n",
    "\n",
    "# scale features and target\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "train_x_scaled = x_scaler.fit_transform(train_data[x])\n",
    "test_x_scaled = x_scaler.transform(test_data[x])\n",
    "train_y_scaled = y_scaler.fit_transform(train_y)\n",
    "test_y_scaled = y_scaler.transform(test_y)\n",
    "\n",
    "# create training sequences\n",
    "train_seq_x, train_seq_y = create_sequences(train_x_scaled,\n",
    "                                            train_y_scaled,\n",
    "                                            seq_length)\n",
    "train_seq_x = train_seq_x.reshape(-1, seq_length, len(x))\n",
    "\n",
    "# model training\n",
    "input_shape = (seq_length, len(x))\n",
    "model = build_lstm_model(input_shape)\n",
    "model = compile_model(model)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_seq_x, train_seq_y,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1)\n",
    "\n",
    "model.save('bilstm_volatility_model.keras')\n",
    "\n",
    "# plot training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='--', linewidth=2)\n",
    "plt.title('Training vs. Validation Loss (Volatility Forecasting)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90071ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Testing and Prediction\n",
    "def generate_test_sequences(train_x_scaled,\n",
    "                            test_x_scaled,\n",
    "                            test_y_scaled,\n",
    "                            seq_length):\n",
    "    combined = np.concatenate([train_x_scaled[-seq_length:], test_x_scaled],\n",
    "                              axis=0)\n",
    " \n",
    "    test_seq_x, test_seq_y = [], []\n",
    "    for i in range(seq_length, len(combined)):\n",
    "        test_seq_x.append(combined[i - seq_length:i])\n",
    "        test_seq_y.append(test_y_scaled[i - seq_length])    \n",
    "    return np.array(test_seq_x), np.array(test_seq_y) \n",
    "\n",
    "# create sequences for test data\n",
    "scaled_test_seq_x, scaled_test_seq_y = generate_test_sequences(\n",
    "    train_x_scaled,\n",
    "    test_x_scaled,\n",
    "    test_y_scaled,\n",
    "    seq_length)\n",
    "\n",
    "# prediction\n",
    "y_pred_scaled = model.predict(scaled_test_seq_x)\n",
    "\n",
    "# inverse transform to original scale\n",
    "y_pred_actual = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_actual = y_scaler.inverse_transform(scaled_test_seq_y.reshape(-1, 1))\n",
    "\n",
    "# plotting function\n",
    "def plot_forecast_vs_actual(y_test_actual, y_pred_actual, date_series):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(date_series, y_test_actual, label=\"Actual Volatility\", color='blue')\n",
    "    plt.plot(date_series, y_pred_actual, label=\"Predicted Volatility\", color='red')\n",
    "    plt.title(\"BiLSTM Forecast vs. Actual (Test Set)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Volatility\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# align dates\n",
    "aligned_test_dates = test_data['date'].iloc[-len(y_test_actual):].reset_index(drop=True)\n",
    "\n",
    "# plot the forecast\n",
    "plot_forecast_vs_actual(y_test_actual.flatten(), y_pred_actual.flatten(), aligned_test_dates)\n",
    "\n",
    "mae, mse = mean_absolute_error(y_test_actual, y_pred_actual), mean_squared_error(y_test_actual, y_pred_actual)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"BiLSTM - MAE: {mae:.6f} | MSE: {mse:.6f} | RMSE: {rmse:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f801c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of Sample Forecasting\n",
    "def forecast_out_of_sample(model,\n",
    "                           test_x_scaled,\n",
    "                           oos_x_scaled,\n",
    "                           oos_y_scaled,\n",
    "                           seq_length,\n",
    "                           y_scaler):\n",
    "    combined_input = np.concatenate([test_x_scaled[-seq_length:], oos_x_scaled],\n",
    "                                    axis=0)\n",
    "\n",
    "    oos_seq_x, oos_seq_y = [], []\n",
    "    for i in range(seq_length, len(combined_input)):\n",
    "        oos_seq_x.append(combined_input[i - seq_length:i])\n",
    "        oos_seq_y.append(oos_y_scaled[i - seq_length])\n",
    "\n",
    "    oos_seq_x = np.array(oos_seq_x)\n",
    "    oos_seq_y = np.array(oos_seq_y)\n",
    "    scaled_oos_pred = model.predict(oos_seq_x)\n",
    "    oos_pred = y_scaler.inverse_transform(scaled_oos_pred)\n",
    "    oos_actual = y_scaler.inverse_transform(oos_seq_y.reshape(-1, 1))\n",
    "    return oos_actual, oos_pred\n",
    "\n",
    "# scale out of sample features and target\n",
    "oos_x_scaled = x_scaler.transform(out_of_sample_data[x])\n",
    "oos_y = out_of_sample_data[[y]].values\n",
    "oos_y_scaled = y_scaler.transform(oos_y)\n",
    "\n",
    "# forecast\n",
    "y_oos_actual, y_oos_pred = forecast_out_of_sample(\n",
    "    model,\n",
    "    test_x_scaled,\n",
    "    oos_x_scaled,\n",
    "    oos_y_scaled,\n",
    "    seq_length,\n",
    "    y_scaler)\n",
    "\n",
    "# plot forecast\n",
    "dates_oos = out_of_sample_data['date'].iloc[seq_length:].reset_index(drop=True)\n",
    "\n",
    "y_oos_actual = y_oos_actual[:len(dates_oos)]  \n",
    "y_oos_pred = y_oos_pred[:len(dates_oos)]     \n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates_oos, y_oos_actual, label='Actual Volatility', color='blue')\n",
    "plt.plot(dates_oos, y_oos_pred, label='Predicted Volatility', color='red')\n",
    "plt.title('BiLSTM Out-of-Sample Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mae_, mse_ = mean_absolute_error(y_oos_actual, y_oos_pred), mean_squared_error(y_oos_actual, y_oos_pred)\n",
    "rmse_ = np.sqrt(mse_)\n",
    "print(f\"BiLSTM - MAE: {mae_:.6f} | MSE: {mse_:.6f} | RMSE: {rmse_:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metrics\n",
    "mae, mse = mean_absolute_error(y_test_actual, y_pred_actual), mean_squared_error(y_test_actual, y_pred_actual)\n",
    "rmse = np.sqrt(mse)\n",
    "test_metrics = f\"Test Metrics - MAE: {mae:.6f} | MSE: {mse:.6f} | RMSE: {rmse:.6f}\"\n",
    "\n",
    "# Out-of-sample metrics\n",
    "mae_, mse_ = mean_absolute_error(y_oos_actual, y_oos_pred), mean_squared_error(y_oos_actual, y_oos_pred)\n",
    "rmse_ = np.sqrt(mse_)\n",
    "oos_metrics = f\"Out-of-Sample Metrics - MAE: {mae_:.6f} | MSE: {mse_:.6f} | RMSE: {rmse_:.6f}\"\n",
    "\n",
    "# Save to text files\n",
    "with open('test_metrics_bilstm.txt', 'w') as f:\n",
    "    f.write(test_metrics)\n",
    "\n",
    "with open('oos_metrics_bilstm.txt', 'w') as f:\n",
    "    f.write(oos_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
